---
title: "Does Region Shapes the Wage Gap Between Black and Non-Black Male Workers?"
subtitle: "Case Study 2"
author: ""
date: "November 14, 2025"
format:
  pdf:
    geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in
execute:
  echo: true
  message: false
  warning: false
---

::: {style="text-align:center; font-size:1.2em; margin-top:1em;"}
Radiah Khan · Catherine Weeks · Mercer Mercer · Nafisa Mohammad
:::

## Introduction

The United States Census Bureau, starting in 1940, has conducted a monthly survey of the labor force known as the Current Population Survey (CPS). The CPS is used to provide current estimates of the economic status. In this Case Study, we aim to address the question. First, were Black males paid less than non-Black males in the same region, with the same levels of education and experience? The motivation behind this question is to determine how racial inequality in the labor force is reflected in wage gaps across the US.

## Data Description

In this case study, we are working with the ex1029 data set available in the Sleuth2 library. This data set represents a sample of 25,632 male respondents to the March 1988 U.S. Current Population Survey that is administered monthly by the U.S. Census Bureau. The variables include:

-   `Wage` Weekly wage in 1992 USD
-   `Education` Years of education
-   `Experience` Years of work experience
-   `Black` Indicator of whether the respondent was black (yes or no)
-   `Region` Region of residence (Northeast, Midwest, South or West)

```{r, include= FALSE}
library(tidyverse)
library(ggplot2)
library(broom)
library(flextable)
library(Sleuth2)
library(kableExtra)
install.packages("GGally")

wages <- Sleuth2::ex1029
wages
```

### Data Wrangling

Before analysis, we checked how many missing observations were present in this data set. Using the `is.na()` and `colSums()` functions, we confirmed that there were no missing observations, so no rows were removed and therefore the dataset used in our analysis contains 25,632 complete observations.

```{r, include=FALSE}
#Check for n/a values
sum(is.na(wages))
colSums(is.na(wages))
```

```{r}
wages_summary_table <-summary(wages)
wages_summary_table

```

To further prepare for visualization and modeling, a new categorical variable, `exp_group` was created by grouping `Experience` into four intervals: 0-20 years, 21-40 years, 41-60 years, and 60+ years of experience.

```{r}
#Making the exprience years into groups 
wages_exp_group <- wages |>
  mutate(exp_group = case_when(
    Experience < 21 ~ "0–20",
    Experience < 41 ~ "20–40",
    Experience < 61 ~ "41-60",
  
    TRUE     ~ "60+"
  ))
head(wages_exp_group, 5)   
```

To visualize regional differences, we computed the average weekly wage by region and race and the average education level by region and race.

```{r}
#Grouping the data for region and average wage
wages_region_avg_wage <- wages |>
  select(Wage, Black, Region) |>
  group_by(Region, Black) |>
  summarise(avg_wage_region = mean(Wage, na.rm = TRUE))|>
  ungroup()
head(wages_region_avg_wage,5)
```

```{r}
#Grouping the data for experience group and region
wages_exp_group_region <- wages_exp_group |>
  mutate(Race = ifelse(Black == "Yes", "Black", "Non-Black")) |>
  group_by(Region, Race, exp_group) |>
  summarise(avg_wage = mean(Wage, na.rm = TRUE), .groups = "drop")
```

The visualization below shows how average wages increase with experience across all regions and that Black respondents consistently earn lower wages than non-Black respondents.

```{r}
#Plotting the experience group variable and avg wage by race
ggplot(wages_exp_group_region, 
       aes(x = exp_group, y = avg_wage, fill = Race)) +
  geom_col(position = position_dodge(width = 0.7)) +
  facet_wrap(~ Region) +
  labs(title = "Average Wage by Experience Group among Races",
       x = "Experience Group (years)",
       y = "Average Wage") +
  coord_flip() +
 scale_fill_manual(values = c("#9BE68E", "#5A63FF"))+
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

```{r}
#get averages of education per region
wages_edu_group_region <- wages |>
  group_by(Region, Black) |>
  summarise(avg_education = mean(Education)) |>
  ungroup()
```

```{r, include= FALSE}
graph.labels <- c("Yes"="Black","No" = "Non-Black")
```

```{r}
#Graph for Average Education by Region and Race, USA
ggplot(wages_edu_group_region, aes(x = avg_education, y = Region, fill = Black)) +
  geom_col() +
  facet_grid(~Black,labeller = labeller(Black = graph.labels) )+
  labs(
    title = "Average Education by Region and Race, USA",
    x = "Average Education (in Years of Schooling)",
    y = "Region"
  ) +
 scale_fill_manual(values = c("#9BE68E", "#5A63FF"))+
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))+coord_flip()
```

#plotting a graph exploring Avg pay by region faceted by race

```{r, echo=FALSE}
#creating new labels for the facet wrapped variables 

wages_region_avg_wage |> ggplot(aes(x=avg_wage_region, y = Region, fill = Black)) + 
  geom_col()+ 
  facet_grid(~Black,labeller = labeller(Black = graph.labels) )+
  coord_flip() +labs(title = "Average Pay in Each USA Region by Race", x= "Average Weekly Wage")+
  theme_bw() +
  scale_fill_manual(values = c("#9BE68E", "#5A63FF"))+
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))+coord_flip()
```

#### Preparing for Regression Analysis

Before modeling, we convert the Black and Region columns into categorical variables. The relevel call sets "No" as the baseline group so model coefficients for Black compare other levels to non‑Black respondents.

```{r, include=FALSE}
#factoring the categorical variables in the wage data set
wages$Black <- factor(wages$Black)
wages$Region <- factor(wages$Region)

#setting the new reference level
wages$Black <- relevel(wages$Black, ref = "No")
```

We fit a multiple regression model predicting Wage using Education, Experience, Black, Region, and the Black-by-Region interaction. Then prints the summary of the model results.

$$E[Wage|Education,Experience,Race,Region]= \beta_0 + \beta_1Education \\+ \beta_2Experience+ \beta_3Race +
\beta_4NorthEast +\beta_5South + \beta_6West \\+ \beta_7Race*NorthEast + \beta_8Race*South \beta_9Race*West$$

Here the variables are Wages representing the weekly wages, Education representing years of education, Experience representing years of experience, Race representing whether a respondent was black our reference level here is non black respondents, and Region being split up into Northeast, Midwest, South, and West with our reference level set as the Midwest.

```{r, include=FALSE}
#MLM model
mlm_model_untransformed <- lm(Wage ~ Education  + Experience + Black * Region, data = wages)
summary(mlm_model_untransformed)

#Prettifying it by adding tables : Making it a data frame first to table it
mlm_untransformed_df <- tidy(mlm_model_untransformed, conf.int = TRUE)
flextable(mlm_untransformed_df)|>
  set_caption("Regression Summary of the Untransformed Model: Predicting Wage")|>
  autofit()|>
  theme_apa()
```

The following two graphs are checking key regression assumptions to see if our model violates the conditions of linearity, normality, and equal variance. The residuals vs. fitted plot checks linearity and equal variance: we want the residuals scattered randomly around zero with no clear curve and roughly the same vertical spread across the range of fitted values (a funnel shape indicates heteroscedasticity).

```{r}
# Checking Linearity and Equal Variance
ggplot(mlm_model_untransformed |> augment(), aes(x = .fitted, y = .resid))+
  geom_point()+
  geom_hline(yintercept = 0, col = "red")+
  labs(title = "Residual Plot (Untransformed Model)" ,
       x = "Fitted Value",
       y = "Residuals")+
  theme_minimal()+
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))

```

```{r}
# Checking for the normality condition
mlm_model_untransformed |>
  augment() |> ggplot(aes(sample = .resid)) + geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q Plot (Untransformed Model) ", x = "Quantilies", y = "Sample Outcomes") + 
  theme_minimal()+
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

The Q–Q plot checks whether the residuals are approximately Normal: points should lie close to the reference line; If points pull away from the line, it suggests the residuals aren’t following a normal pattern. That matters because our standard errors, confidence intervals, and p-values assume normal residuals. Therefore, if the assumption is false, those numbers can be misleading. Thus, we will perform log transformation on our response variable in our case will be the Wage.

```{r}
#MLM model with log scaled y axis
mlm_model <- lm(log(Wage) ~ Education  + Experience + Black * Region, data = wages)
summary(mlm_model)

```

$$E[log(wage)|Education,Experience,Race,Region]= \beta_0 + \beta_1Education \\+ \beta_2Experience+ \beta_3Race +
\beta_4NorthEast +\beta_5South + \beta_6West \\+ \beta_7Race*NorthEast + \beta_8Race*South \beta_9Race*West$$

```{r}
#Prettifying it 
mlm_transformed_df <- tidy(mlm_model, conf.int = TRUE)
flextable(mlm_transformed_df)|>
  set_caption("Regression Summary of the Transformed Model: Predicting Wage")|>
  autofit()|>
  theme_apa()

```

```{r}
# Checking Linearity and Equal Variance
ggplot(mlm_model |> augment(), aes(x = .fitted, y = .resid))+
  geom_point()+
  geom_hline(yintercept = 0, col = "red")+
  labs(title = "Residual Plot (Transformed Model)",
       x = "Fitted",
       y = "Residuals") + 
  theme_minimal()+
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

```{r}
# Checking for the normality condition
mlm_model |>
  augment() |> ggplot(aes(sample = .resid)) + geom_qq() +
  geom_qq_line() +
  labs(title = "Q-Q Plot (Transformed model) ", x = "Quantilies", y = "Sample Outcomes") + 
  theme_minimal()+
    theme(plot.title = element_text(hjust = 0.5, face = "bold"))
```

Untransformed model: the residuals vs fitted plot had a clear pattern that the residuals followed showing that there was no random scattering for the residuals. This indicates that the residuals got larger as fitted values increased. In addition, a few points stuck way above the rest clearly showing that the residuals were not centered at zero. The Q–Q plot showed a strong right‑side hook, meaning the residuals had a heavy right tail. It's important to point out that the residuals that fell above the reference line were big numbers. In summary, the errors were uneven and skewed, so the model was being pulled by a few very large wages.

Transformed model (log Wage): the residuals vs fitted plot now looks evenly distributed with residuals centered on zero with similar spread across fitted values (no obvious shape pattern). The Q–Q plot is also much closer to the straight line, so residuals are more like a Normal distribution. With these improvements our transformed model now meets the usual regression assumptions (linearity, equal variance, normality). With our model now better fitted we can now move on to proofing our research question. However, although the transformed model is much better, it is not perfect as it still shows curved tails on extreme sides of the plot.

```{r}
wages_reduced_model <- lm(log(Wage) ~ Education + Experience + Black + Region, data = wages)
summary(wages_reduced_model)
wages_reduced_df <- tidy(wages_reduced_model, conf.int = TRUE)
flextable(wages_reduced_df)|>
  set_caption("Regression Summary of the Reduced Model: Predicting Wage")|>
  autofit()|>
  theme_apa()

```

### Conducting the hypothesis test

For conducting the hypothesis test we will use the nested F test method.

The full model contains $9$ predictor terms and the reduced model contains $6$ predictors. So our extra term is $8-6$ = 3 terms.

$H_0 : \beta_j = 0$ for all $3$ predictor terms being dropped from the full model. $H_A : \beta_j \neq 0$ for at least one of the $3$ predictor terms being dropped from the full model.

The significance level(\alpha) for this test is $0.05$.

```{r ftest-table}
#Conducting the nested F test
f_results <- anova(wages_reduced_model,mlm_model)
anova_df <- as.data.frame(f_results)
flextable(anova_df)|>
  set_caption("F-test Result Summary")|>
  autofit()|>
  theme_apa()
```

From the results, the F statistic is $1.145$ and the p-value is 0.23. The Black × Region interaction is not statistically significant because our p = 0.23 \> α = 0.05. Therefore we fail to reject the null that the interaction coefficients are zero, and there is no evidence that the Black–non‑Black wage gap differs across the four regions after adjusting for education and experience.

### Analysis

From the F-test results in Table @ref(tab:ftest-table), we can see that the test result was not statistically significant. There is a clear wage gap across the nation that doesn't significantly differ based on region. While Black men in the USA are paid less than Non-Black men, this pay gap is consistent and doesn't expand or shrink regionally. In a lot of the plots, we also saw a difference in which age group participates in the labor force.

Some limitations of this analysis are that this data set only represents one month of weekly wages, and doesn't represent seasonal work. The research question also only looks at the wages of men, and doesn't take women and labor that is traditionally performed by women (childcare, caring for elderly family) into account. Another large limitation is that our data only separates individuals into two groups; Black and non-Black which disregards the potential influence of other races, especially in areas that have high populations of Hispanic individuals, for example. This data also only represents wages that were reported to the government, and excludes any shadow work that may have occurred.Finally, the data set used is very old, and we can't use these findings to draw conclusions about the current state of our economy.
